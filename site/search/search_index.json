{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BehaveML Supervised learning for animal behavior. Interprets pose-tracking files (currently only from DLC), behavior annotations (currently only from BORIS) to train a behavior classifier. Installation pip install behaveml Can install optional extras with: pip install numpy, cython pip install behaveml[all] This includes matplotlib, keras, and Linderman lab's state-space model package, ssm. Note that installing ssm requires cython and numpy for the build, so must be already present in the environment. Quickstart Import from glob import glob from behaveml import VideosetDataFrame, clone_metadata from behaveml import compute_dl_probability_features, compute_mars_features Gather the DLC and BORIS tracking and annotation files tracking_files = glob('./tests/data/dlc/*.csv') boris_files = glob('./tests/data/boris/*.csv') Setup some parameters frame_length = None # (float) length of entire horizontal shot units = None # (str) units frame_length is given in fps = 30 # (int) frames per second resolution = (1200, 1600) # (tuple) HxW in pixels Create a parameter object and video dataset metadata = clone_metadata(tracking_files, label_files = boris_files, frame_length = frame_length, fps = fps, units = units, resolution = resolution) dataset = VideosetDataFrame(metadata) Now create features on this dataset dataset.add_features(compute_dl_probability_features, featureset_name = '1dcnn', add_to_features = True) dataset.add_features(compute_mars_features, featureset_name = 'MARS', add_to_features = True) Now access a features table, labels, and groups for learning with dataset.features, dataset.labels, dataset.groups . For example: from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier from sklearn.model_selection import cross_val_predict from sklearn.metrics import accuracy_score model = RandomForestClassifier() predictions = cross_val_predict(model, dataset.features, dataset.labels, dataset.groups) score = accuracy_score(dataset.labels, predictions)","title":"Home"},{"location":"#behaveml","text":"Supervised learning for animal behavior. Interprets pose-tracking files (currently only from DLC), behavior annotations (currently only from BORIS) to train a behavior classifier.","title":"BehaveML"},{"location":"#installation","text":"pip install behaveml Can install optional extras with: pip install numpy, cython pip install behaveml[all] This includes matplotlib, keras, and Linderman lab's state-space model package, ssm. Note that installing ssm requires cython and numpy for the build, so must be already present in the environment.","title":"Installation"},{"location":"#quickstart","text":"Import from glob import glob from behaveml import VideosetDataFrame, clone_metadata from behaveml import compute_dl_probability_features, compute_mars_features Gather the DLC and BORIS tracking and annotation files tracking_files = glob('./tests/data/dlc/*.csv') boris_files = glob('./tests/data/boris/*.csv') Setup some parameters frame_length = None # (float) length of entire horizontal shot units = None # (str) units frame_length is given in fps = 30 # (int) frames per second resolution = (1200, 1600) # (tuple) HxW in pixels Create a parameter object and video dataset metadata = clone_metadata(tracking_files, label_files = boris_files, frame_length = frame_length, fps = fps, units = units, resolution = resolution) dataset = VideosetDataFrame(metadata) Now create features on this dataset dataset.add_features(compute_dl_probability_features, featureset_name = '1dcnn', add_to_features = True) dataset.add_features(compute_mars_features, featureset_name = 'MARS', add_to_features = True) Now access a features table, labels, and groups for learning with dataset.features, dataset.labels, dataset.groups . For example: from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier from sklearn.model_selection import cross_val_predict from sklearn.metrics import accuracy_score model = RandomForestClassifier() predictions = cross_val_predict(model, dataset.features, dataset.labels, dataset.groups) score = accuracy_score(dataset.labels, predictions)","title":"Quickstart"},{"location":"api-docs/","text":"API Overview Modules config : Configuration options for behaveml functions. dl dl.dl_features dl.dl_generators dl.dl_models dl.feature_engineering dl.grid_searches features : Functions to take pose tracks and compute a set of features from them interpolation io : Loading and saving tracking and behavior annotation files mars_features ml : Machine learning functions plot unsupervised utils : Small helper utilities video : Basic video tracking and behavior class that houses data Classes dl_features.Trainer dl_generators.MABe_Generator features.Features io.BufferedIOBase : Base class for buffered IO objects. io.IOBase : The abstract base class for all I/O classes, acting on streams of io.RawIOBase : Base class for raw binary I/O. io.TextIOBase : Base class for text I/O. io.UnsupportedOperation plot.MplColorHelper video.MLDataFrame : DataFrame useful for interfacing between pandas and sklearn. Stores a data video.VideosetDataFrame Functions dl_features.compute_dl_probability_features dl_features.convert_to_mars_format dl_features.convert_to_pandas_df dl_features.lrs dl_features.normalize_data dl_features.run_task dl_features.seed_everything dl_generators.features_distances dl_generators.features_distances_normalized dl_generators.features_identity dl_generators.features_mars dl_generators.features_mars_distr dl_generators.features_via_sklearn dl_generators.make_df dl_models.build_baseline_model feature_engineering.augment_features feature_engineering.boiler_plate feature_engineering.make_features_distances feature_engineering.make_features_mars feature_engineering.make_features_mars_distr feature_engineering.make_features_mars_reduced feature_engineering.make_features_social feature_engineering.make_features_velocities interpolation.interpolate_lowconf_points : Interpolate raw tracking points if their probabilities are available. io.get_sample_data : Load a sample dataset of 5 mice social interaction videos. Each video is approx. 5 minutes in duration io.get_sample_data_paths : Get path to sample data files provided with package. io.load_data : Load an object from a pickle file io.load_sklearn_model io.read_DLC_tracks : Read in tracks from DLC. io.read_boris_annotation : Read behavior annotation from BORIS exported csv file io.rename_df_cols : Rename dataframe columns io.save_DLC_tracks_h5 : Save DLC tracks in h5 format. io.save_sklearn_model io.uniquifier : Return a sequence (e.g. list) with unique elements only, but maintaining original list order mars_features.compute_distance_features mars_features.compute_mars_features mars_features.compute_mars_reduced_features mars_features.compute_social_features mars_features.compute_velocity_features plot.create_ethogram_video : Overlay ethogram on top of source video with ffmpeg plot.create_mosaic_video : Take a set of video clips and turn them into a mosaic using ffmpeg plot.create_sample_videos : Create a sample of videos displaying the labeled behaviors using ffmpeg. plot.plot_embedding : Scatterplot of a 2D TSNE or UMAP embedding from the dataset. plot.plot_ethogram : Simple ethogram of one video, up to a certain frame number. plot.plot_unsupervised_results : Set of plots for unsupervised behavior clustering results unsupervised.cluster_behaviors : Cluster behaviors based on dimensionality reduction, kernel density estimation, and watershed clustering. unsupervised.compute_density : Compute kernel density estimate of embedding. unsupervised.compute_morlet unsupervised.compute_tsne_embedding : Compute TSNE embedding. unsupervised.compute_watershed : Compute watershed clustering of a density matrix. utils.checkFFMPEG : Check for ffmpeg dependencies video.clone_metadata : Prepare a metadata dictionary for defining a VideosetDataFrame. video.load_videodataset : Load VideosetDataFrame from file. This file was automatically generated via lazydocs .","title":"Overview"},{"location":"api-docs/#api-overview","text":"","title":"API Overview"},{"location":"api-docs/#modules","text":"config : Configuration options for behaveml functions. dl dl.dl_features dl.dl_generators dl.dl_models dl.feature_engineering dl.grid_searches features : Functions to take pose tracks and compute a set of features from them interpolation io : Loading and saving tracking and behavior annotation files mars_features ml : Machine learning functions plot unsupervised utils : Small helper utilities video : Basic video tracking and behavior class that houses data","title":"Modules"},{"location":"api-docs/#classes","text":"dl_features.Trainer dl_generators.MABe_Generator features.Features io.BufferedIOBase : Base class for buffered IO objects. io.IOBase : The abstract base class for all I/O classes, acting on streams of io.RawIOBase : Base class for raw binary I/O. io.TextIOBase : Base class for text I/O. io.UnsupportedOperation plot.MplColorHelper video.MLDataFrame : DataFrame useful for interfacing between pandas and sklearn. Stores a data video.VideosetDataFrame","title":"Classes"},{"location":"api-docs/#functions","text":"dl_features.compute_dl_probability_features dl_features.convert_to_mars_format dl_features.convert_to_pandas_df dl_features.lrs dl_features.normalize_data dl_features.run_task dl_features.seed_everything dl_generators.features_distances dl_generators.features_distances_normalized dl_generators.features_identity dl_generators.features_mars dl_generators.features_mars_distr dl_generators.features_via_sklearn dl_generators.make_df dl_models.build_baseline_model feature_engineering.augment_features feature_engineering.boiler_plate feature_engineering.make_features_distances feature_engineering.make_features_mars feature_engineering.make_features_mars_distr feature_engineering.make_features_mars_reduced feature_engineering.make_features_social feature_engineering.make_features_velocities interpolation.interpolate_lowconf_points : Interpolate raw tracking points if their probabilities are available. io.get_sample_data : Load a sample dataset of 5 mice social interaction videos. Each video is approx. 5 minutes in duration io.get_sample_data_paths : Get path to sample data files provided with package. io.load_data : Load an object from a pickle file io.load_sklearn_model io.read_DLC_tracks : Read in tracks from DLC. io.read_boris_annotation : Read behavior annotation from BORIS exported csv file io.rename_df_cols : Rename dataframe columns io.save_DLC_tracks_h5 : Save DLC tracks in h5 format. io.save_sklearn_model io.uniquifier : Return a sequence (e.g. list) with unique elements only, but maintaining original list order mars_features.compute_distance_features mars_features.compute_mars_features mars_features.compute_mars_reduced_features mars_features.compute_social_features mars_features.compute_velocity_features plot.create_ethogram_video : Overlay ethogram on top of source video with ffmpeg plot.create_mosaic_video : Take a set of video clips and turn them into a mosaic using ffmpeg plot.create_sample_videos : Create a sample of videos displaying the labeled behaviors using ffmpeg. plot.plot_embedding : Scatterplot of a 2D TSNE or UMAP embedding from the dataset. plot.plot_ethogram : Simple ethogram of one video, up to a certain frame number. plot.plot_unsupervised_results : Set of plots for unsupervised behavior clustering results unsupervised.cluster_behaviors : Cluster behaviors based on dimensionality reduction, kernel density estimation, and watershed clustering. unsupervised.compute_density : Compute kernel density estimate of embedding. unsupervised.compute_morlet unsupervised.compute_tsne_embedding : Compute TSNE embedding. unsupervised.compute_watershed : Compute watershed clustering of a density matrix. utils.checkFFMPEG : Check for ffmpeg dependencies video.clone_metadata : Prepare a metadata dictionary for defining a VideosetDataFrame. video.load_videodataset : Load VideosetDataFrame from file. This file was automatically generated via lazydocs .","title":"Functions"},{"location":"api-docs/config/","text":"module config Configuration options for behaveml functions. Global Variables global_config This file was automatically generated via lazydocs .","title":"Config"},{"location":"api-docs/config/#module-config","text":"Configuration options for behaveml functions.","title":"module config"},{"location":"api-docs/config/#global-variables","text":"global_config This file was automatically generated via lazydocs .","title":"Global Variables"},{"location":"api-docs/dl.dl_features/","text":"module dl.dl_features Global Variables sweeps_baseline feature_spaces has_keras THIS_FILE_DIR function seed_everything seed_everything(seed=2012) function normalize_data normalize_data(orig_pose_dictionary) function run_task run_task( vocabulary, test_data, config_name, build_model, skip_test_prediction=False, seed=2021, Generator=<class 'behaveml.dl.dl_generators.MABe_Generator'>, use_callbacks=False, params=None, use_conv=True ) function lrs lrs(epoch, lr, freq=10) function convert_to_mars_format convert_to_mars_format(df, colnames, animal_setup) function convert_to_pandas_df convert_to_pandas_df(data, colnames=None) function compute_dl_probability_features compute_dl_probability_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) class Trainer method __init__ __init__( feature_dim, num_classes, test_data=None, class_to_number=None, past_frames=0, future_frames=0, frame_gap=1, use_conv=False, build_model=<function build_baseline_model at 0x7eff32a9cd40>, Generator=<class 'behaveml.dl.dl_generators.MABe_Generator'>, use_callbacks=False, learning_decay_freq=10, featurizer=<function features_identity at 0x7f0071865cb0> ) method delete_model delete_model() method get_test_prediction_probabilities get_test_prediction_probabilities() method initialize_model initialize_model(**kwargs) method train train(model_params, class_weight=None, n_folds=5) This file was automatically generated via lazydocs .","title":"Dl.dl features"},{"location":"api-docs/dl.dl_features/#module-dldl_features","text":"","title":"module dl.dl_features"},{"location":"api-docs/dl.dl_features/#global-variables","text":"sweeps_baseline feature_spaces has_keras THIS_FILE_DIR","title":"Global Variables"},{"location":"api-docs/dl.dl_features/#function-seed_everything","text":"seed_everything(seed=2012)","title":"function seed_everything"},{"location":"api-docs/dl.dl_features/#function-normalize_data","text":"normalize_data(orig_pose_dictionary)","title":"function normalize_data"},{"location":"api-docs/dl.dl_features/#function-run_task","text":"run_task( vocabulary, test_data, config_name, build_model, skip_test_prediction=False, seed=2021, Generator=<class 'behaveml.dl.dl_generators.MABe_Generator'>, use_callbacks=False, params=None, use_conv=True )","title":"function run_task"},{"location":"api-docs/dl.dl_features/#function-lrs","text":"lrs(epoch, lr, freq=10)","title":"function lrs"},{"location":"api-docs/dl.dl_features/#function-convert_to_mars_format","text":"convert_to_mars_format(df, colnames, animal_setup)","title":"function convert_to_mars_format"},{"location":"api-docs/dl.dl_features/#function-convert_to_pandas_df","text":"convert_to_pandas_df(data, colnames=None)","title":"function convert_to_pandas_df"},{"location":"api-docs/dl.dl_features/#function-compute_dl_probability_features","text":"compute_dl_probability_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs )","title":"function compute_dl_probability_features"},{"location":"api-docs/dl.dl_features/#class-trainer","text":"","title":"class Trainer"},{"location":"api-docs/dl.dl_features/#method-__init__","text":"__init__( feature_dim, num_classes, test_data=None, class_to_number=None, past_frames=0, future_frames=0, frame_gap=1, use_conv=False, build_model=<function build_baseline_model at 0x7eff32a9cd40>, Generator=<class 'behaveml.dl.dl_generators.MABe_Generator'>, use_callbacks=False, learning_decay_freq=10, featurizer=<function features_identity at 0x7f0071865cb0> )","title":"method __init__"},{"location":"api-docs/dl.dl_features/#method-delete_model","text":"delete_model()","title":"method delete_model"},{"location":"api-docs/dl.dl_features/#method-get_test_prediction_probabilities","text":"get_test_prediction_probabilities()","title":"method get_test_prediction_probabilities"},{"location":"api-docs/dl.dl_features/#method-initialize_model","text":"initialize_model(**kwargs)","title":"method initialize_model"},{"location":"api-docs/dl.dl_features/#method-train","text":"train(model_params, class_weight=None, n_folds=5) This file was automatically generated via lazydocs .","title":"method train"},{"location":"api-docs/dl.dl_generators/","text":"module dl.dl_generators Global Variables has_keras function make_df make_df(pts, colnames=None) function features_identity features_identity(inputs) function features_via_sklearn features_via_sklearn(inputs, featurizer) function features_mars features_mars(x) function features_mars_distr features_mars_distr(x) function features_distances features_distances(inputs) function features_distances_normalized features_distances_normalized(inputs) class MABe_Generator method __init__ __init__( pose_dict, batch_size, dim, use_conv, num_classes, augment=False, class_to_number=None, past_frames=0, future_frames=0, frame_gap=1, shuffle=False, mode='fit', featurize=<function features_identity at 0x7f00422d4560> ) method augment_fn augment_fn(x) method on_epoch_end on_epoch_end() This file was automatically generated via lazydocs .","title":"Dl.dl generators"},{"location":"api-docs/dl.dl_generators/#module-dldl_generators","text":"","title":"module dl.dl_generators"},{"location":"api-docs/dl.dl_generators/#global-variables","text":"has_keras","title":"Global Variables"},{"location":"api-docs/dl.dl_generators/#function-make_df","text":"make_df(pts, colnames=None)","title":"function make_df"},{"location":"api-docs/dl.dl_generators/#function-features_identity","text":"features_identity(inputs)","title":"function features_identity"},{"location":"api-docs/dl.dl_generators/#function-features_via_sklearn","text":"features_via_sklearn(inputs, featurizer)","title":"function features_via_sklearn"},{"location":"api-docs/dl.dl_generators/#function-features_mars","text":"features_mars(x)","title":"function features_mars"},{"location":"api-docs/dl.dl_generators/#function-features_mars_distr","text":"features_mars_distr(x)","title":"function features_mars_distr"},{"location":"api-docs/dl.dl_generators/#function-features_distances","text":"features_distances(inputs)","title":"function features_distances"},{"location":"api-docs/dl.dl_generators/#function-features_distances_normalized","text":"features_distances_normalized(inputs)","title":"function features_distances_normalized"},{"location":"api-docs/dl.dl_generators/#class-mabe_generator","text":"","title":"class MABe_Generator"},{"location":"api-docs/dl.dl_generators/#method-__init__","text":"__init__( pose_dict, batch_size, dim, use_conv, num_classes, augment=False, class_to_number=None, past_frames=0, future_frames=0, frame_gap=1, shuffle=False, mode='fit', featurize=<function features_identity at 0x7f00422d4560> )","title":"method __init__"},{"location":"api-docs/dl.dl_generators/#method-augment_fn","text":"augment_fn(x)","title":"method augment_fn"},{"location":"api-docs/dl.dl_generators/#method-on_epoch_end","text":"on_epoch_end() This file was automatically generated via lazydocs .","title":"method on_epoch_end"},{"location":"api-docs/dl.dl_models/","text":"module dl.dl_models Global Variables has_keras function build_baseline_model build_baseline_model( input_dim, layer_channels=(512, 256), dropout_rate=0.0, learning_rate=0.001, conv_size=5, num_classes=4, class_weight=None ) This file was automatically generated via lazydocs .","title":"Dl.dl models"},{"location":"api-docs/dl.dl_models/#module-dldl_models","text":"","title":"module dl.dl_models"},{"location":"api-docs/dl.dl_models/#global-variables","text":"has_keras","title":"Global Variables"},{"location":"api-docs/dl.dl_models/#function-build_baseline_model","text":"build_baseline_model( input_dim, layer_channels=(512, 256), dropout_rate=0.0, learning_rate=0.001, conv_size=5, num_classes=4, class_weight=None ) This file was automatically generated via lazydocs .","title":"function build_baseline_model"},{"location":"api-docs/dl.feature_engineering/","text":"module dl.feature_engineering Global Variables XY_IDS WIDTH HEIGHT function augment_features augment_features(window_size=5, n_shifts=3, mode='shift') function boiler_plate boiler_plate(features_df) function make_features_distances make_features_distances(df, animal_setup) function make_features_mars make_features_mars(df, animal_setup, n_shifts=3, mode='shift') function make_features_mars_distr make_features_mars_distr(x, y) function make_features_mars_reduced make_features_mars_reduced(df, animal_setup, n_shifts=2, mode='diff') function make_features_velocities make_features_velocities(df, animal_setup, n_shifts=5) function make_features_social make_features_social(df, animal_setup, n_shifts=3, mode='shift') This file was automatically generated via lazydocs .","title":"Dl.feature engineering"},{"location":"api-docs/dl.feature_engineering/#module-dlfeature_engineering","text":"","title":"module dl.feature_engineering"},{"location":"api-docs/dl.feature_engineering/#global-variables","text":"XY_IDS WIDTH HEIGHT","title":"Global Variables"},{"location":"api-docs/dl.feature_engineering/#function-augment_features","text":"augment_features(window_size=5, n_shifts=3, mode='shift')","title":"function augment_features"},{"location":"api-docs/dl.feature_engineering/#function-boiler_plate","text":"boiler_plate(features_df)","title":"function boiler_plate"},{"location":"api-docs/dl.feature_engineering/#function-make_features_distances","text":"make_features_distances(df, animal_setup)","title":"function make_features_distances"},{"location":"api-docs/dl.feature_engineering/#function-make_features_mars","text":"make_features_mars(df, animal_setup, n_shifts=3, mode='shift')","title":"function make_features_mars"},{"location":"api-docs/dl.feature_engineering/#function-make_features_mars_distr","text":"make_features_mars_distr(x, y)","title":"function make_features_mars_distr"},{"location":"api-docs/dl.feature_engineering/#function-make_features_mars_reduced","text":"make_features_mars_reduced(df, animal_setup, n_shifts=2, mode='diff')","title":"function make_features_mars_reduced"},{"location":"api-docs/dl.feature_engineering/#function-make_features_velocities","text":"make_features_velocities(df, animal_setup, n_shifts=5)","title":"function make_features_velocities"},{"location":"api-docs/dl.feature_engineering/#function-make_features_social","text":"make_features_social(df, animal_setup, n_shifts=3, mode='shift') This file was automatically generated via lazydocs .","title":"function make_features_social"},{"location":"api-docs/dl.grid_searches/","text":"module dl.grid_searches Global Variables has_keras feature_spaces sweeps_baseline This file was automatically generated via lazydocs .","title":"Dl.grid searches"},{"location":"api-docs/dl.grid_searches/#module-dlgrid_searches","text":"","title":"module dl.grid_searches"},{"location":"api-docs/dl.grid_searches/#global-variables","text":"has_keras feature_spaces sweeps_baseline This file was automatically generated via lazydocs .","title":"Global Variables"},{"location":"api-docs/dl/","text":"module dl This file was automatically generated via lazydocs .","title":"Dl"},{"location":"api-docs/dl/#module-dl","text":"This file was automatically generated via lazydocs .","title":"module dl"},{"location":"api-docs/features/","text":"module features Functions to take pose tracks and compute a set of features from them Global Variables default_tracking_columns mars_feature_maker cnn_probability_feature_maker distance_feature_maker marsreduced_feature_maker social_feature_maker velocity_feature_maker class Features method __init__ __init__(feature_maker: Callable, required_columns: list, **kwargs) method make make(vdf, **kwargs) This file was automatically generated via lazydocs .","title":"Features"},{"location":"api-docs/features/#module-features","text":"Functions to take pose tracks and compute a set of features from them","title":"module features"},{"location":"api-docs/features/#global-variables","text":"default_tracking_columns mars_feature_maker cnn_probability_feature_maker distance_feature_maker marsreduced_feature_maker social_feature_maker velocity_feature_maker","title":"Global Variables"},{"location":"api-docs/features/#class-features","text":"","title":"class Features"},{"location":"api-docs/features/#method-__init__","text":"__init__(feature_maker: Callable, required_columns: list, **kwargs)","title":"method __init__"},{"location":"api-docs/features/#method-make","text":"make(vdf, **kwargs) This file was automatically generated via lazydocs .","title":"method make"},{"location":"api-docs/interpolation/","text":"module interpolation function interpolate_lowconf_points interpolate_lowconf_points( vdf: VideosetDataFrame, filter_out_lowconf: bool = True, filter_out_toofast: bool = True, conf_threshold: float = 0.9, jump_dur: int = 5, speed_threshold: float = 5, in_place=True ) \u2192 DataFrame Interpolate raw tracking points if their probabilities are available. Args: vdf : VideosetDataFrame containing the tracks to interpolate filter_out_lowconf : default True. Whether to filter out low confidence points filter_out_toofast : default True. Whether to filter out tracks that jump too far in a number of frames conf_threshold : default 0.9. Confidence below which to count as uncertain, and to interpolate its value instead jump_dur : default 5. Number of frames to compute velocity which is used as basis for filtering out jumps speed_threshold : default 5. Number of pixels to in_place : default True. Whether to replace data in place Returns: Pandas dataframe with the filtered raw columns. Returns None if opted for in_place modification This file was automatically generated via lazydocs .","title":"Interpolation"},{"location":"api-docs/interpolation/#module-interpolation","text":"","title":"module interpolation"},{"location":"api-docs/interpolation/#function-interpolate_lowconf_points","text":"interpolate_lowconf_points( vdf: VideosetDataFrame, filter_out_lowconf: bool = True, filter_out_toofast: bool = True, conf_threshold: float = 0.9, jump_dur: int = 5, speed_threshold: float = 5, in_place=True ) \u2192 DataFrame Interpolate raw tracking points if their probabilities are available. Args: vdf : VideosetDataFrame containing the tracks to interpolate filter_out_lowconf : default True. Whether to filter out low confidence points filter_out_toofast : default True. Whether to filter out tracks that jump too far in a number of frames conf_threshold : default 0.9. Confidence below which to count as uncertain, and to interpolate its value instead jump_dur : default 5. Number of frames to compute velocity which is used as basis for filtering out jumps speed_threshold : default 5. Number of pixels to in_place : default True. Whether to replace data in place Returns: Pandas dataframe with the filtered raw columns. Returns None if opted for in_place modification This file was automatically generated via lazydocs .","title":"function interpolate_lowconf_points"},{"location":"api-docs/io/","text":"module io Loading and saving tracking and behavior annotation files Global Variables DEFAULT_BUFFER_SIZE SEEK_SET SEEK_CUR SEEK_END XY_IDS XYLIKELIHOOD_IDS function uniquifier uniquifier(seq) Return a sequence (e.g. list) with unique elements only, but maintaining original list order function save_sklearn_model save_sklearn_model(model, fn_out) function load_sklearn_model load_sklearn_model(fn_in) function read_DLC_tracks read_DLC_tracks( fn_in: str, part_renamer: dict = None, animal_renamer: dict = None, read_likelihoods: bool = True ) \u2192 tuple Read in tracks from DLC. Args: fn_in : csv file that has DLC tracks part_renamer : dictionary to rename body parts, if needed animal_renamer : dictionary to rename animals, if needed read_likelihoods : default True. Whether to attach DLC likelihoods to table Returns: Pandas DataFrame with (n_animals 2 n_body_parts) columns plus with filename and frame, List of body parts, List of animals, Columns names for DLC tracks (excluding likelihoods, if read in), Scorer function rename_df_cols rename_df_cols(df: DataFrame, renamer: dict) \u2192 DataFrame Rename dataframe columns Args: df : Pandas dataframe whose columns to rename renamer : dictionary whose key:value pairs define the substitutions to make Returns: The dataframe with renamed columns. function save_DLC_tracks_h5 save_DLC_tracks_h5(df: DataFrame, fn_out: str) \u2192 None Save DLC tracks in h5 format. Args: df : Pandas dataframe to save fn_out : Where to save the dataframe function load_data load_data(fn: str) Load an object from a pickle file Args: fn : The filename Returns: The pickled object. function get_sample_data_paths get_sample_data_paths() Get path to sample data files provided with package. Returns: (tuple) list of DLC tracking file, list of boris annotation files function get_sample_data get_sample_data() Load a sample dataset of 5 mice social interaction videos. Each video is approx. 5 minutes in duration Returns: (VideosetDataFrame) Data frame with the corresponding tracking and behavior annotation files function read_boris_annotation read_boris_annotation(fn_in: str, fps: int, duration: float) \u2192 ndarray Read behavior annotation from BORIS exported csv file Args: fn_in : The filename with BORIS behavior annotations to load fps : Frames per second of video duration : Duration of video Returns: A numpy array which indicates, for all frames, if behavior is occuring (1) or not (0) class BufferedIOBase Base class for buffered IO objects. The main difference with RawIOBase is that the read() method supports omitting the size argument, and does not have a default implementation that defers to readinto(). In addition, read(), readinto() and write() may raise BlockingIOError if the underlying raw stream is in non-blocking mode and not ready; unlike their raw counterparts, they will never return None. A typical implementation should not inherit from a RawIOBase implementation, but wrap one. class IOBase The abstract base class for all I/O classes, acting on streams of bytes. There is no public constructor. This class provides dummy implementations for many methods that derived classes can override selectively; the default implementations represent a file that cannot be read, written or seeked. Even though IOBase does not declare read, readinto, or write because their signatures will vary, implementations and clients should consider those methods part of the interface. Also, implementations may raise UnsupportedOperation when operations they do not support are called. The basic type used for binary data read from or written to a file is bytes. Other bytes-like objects are accepted as method arguments too. In some cases (such as readinto), a writable object is required. Text I/O classes work with str data. Note that calling any method (except additional calls to close(), which are ignored) on a closed stream should raise a ValueError. IOBase (and its subclasses) support the iterator protocol, meaning that an IOBase object can be iterated over yielding the lines in a stream. IOBase also supports the :keyword: with statement. In this example, fp is closed after the suite of the with statement is complete: with open('spam.txt', 'r') as fp: fp.write('Spam and eggs!') class RawIOBase Base class for raw binary I/O. class TextIOBase Base class for text I/O. This class provides a character and line based interface to stream I/O. There is no readinto method because Python's character strings are immutable. There is no public constructor. class UnsupportedOperation This file was automatically generated via lazydocs .","title":"Io"},{"location":"api-docs/io/#module-io","text":"Loading and saving tracking and behavior annotation files","title":"module io"},{"location":"api-docs/io/#global-variables","text":"DEFAULT_BUFFER_SIZE SEEK_SET SEEK_CUR SEEK_END XY_IDS XYLIKELIHOOD_IDS","title":"Global Variables"},{"location":"api-docs/io/#function-uniquifier","text":"uniquifier(seq) Return a sequence (e.g. list) with unique elements only, but maintaining original list order","title":"function uniquifier"},{"location":"api-docs/io/#function-save_sklearn_model","text":"save_sklearn_model(model, fn_out)","title":"function save_sklearn_model"},{"location":"api-docs/io/#function-load_sklearn_model","text":"load_sklearn_model(fn_in)","title":"function load_sklearn_model"},{"location":"api-docs/io/#function-read_dlc_tracks","text":"read_DLC_tracks( fn_in: str, part_renamer: dict = None, animal_renamer: dict = None, read_likelihoods: bool = True ) \u2192 tuple Read in tracks from DLC. Args: fn_in : csv file that has DLC tracks part_renamer : dictionary to rename body parts, if needed animal_renamer : dictionary to rename animals, if needed read_likelihoods : default True. Whether to attach DLC likelihoods to table Returns: Pandas DataFrame with (n_animals 2 n_body_parts) columns plus with filename and frame, List of body parts, List of animals, Columns names for DLC tracks (excluding likelihoods, if read in), Scorer","title":"function read_DLC_tracks"},{"location":"api-docs/io/#function-rename_df_cols","text":"rename_df_cols(df: DataFrame, renamer: dict) \u2192 DataFrame Rename dataframe columns Args: df : Pandas dataframe whose columns to rename renamer : dictionary whose key:value pairs define the substitutions to make Returns: The dataframe with renamed columns.","title":"function rename_df_cols"},{"location":"api-docs/io/#function-save_dlc_tracks_h5","text":"save_DLC_tracks_h5(df: DataFrame, fn_out: str) \u2192 None Save DLC tracks in h5 format. Args: df : Pandas dataframe to save fn_out : Where to save the dataframe","title":"function save_DLC_tracks_h5"},{"location":"api-docs/io/#function-load_data","text":"load_data(fn: str) Load an object from a pickle file Args: fn : The filename Returns: The pickled object.","title":"function load_data"},{"location":"api-docs/io/#function-get_sample_data_paths","text":"get_sample_data_paths() Get path to sample data files provided with package. Returns: (tuple) list of DLC tracking file, list of boris annotation files","title":"function get_sample_data_paths"},{"location":"api-docs/io/#function-get_sample_data","text":"get_sample_data() Load a sample dataset of 5 mice social interaction videos. Each video is approx. 5 minutes in duration Returns: (VideosetDataFrame) Data frame with the corresponding tracking and behavior annotation files","title":"function get_sample_data"},{"location":"api-docs/io/#function-read_boris_annotation","text":"read_boris_annotation(fn_in: str, fps: int, duration: float) \u2192 ndarray Read behavior annotation from BORIS exported csv file Args: fn_in : The filename with BORIS behavior annotations to load fps : Frames per second of video duration : Duration of video Returns: A numpy array which indicates, for all frames, if behavior is occuring (1) or not (0)","title":"function read_boris_annotation"},{"location":"api-docs/io/#class-bufferediobase","text":"Base class for buffered IO objects. The main difference with RawIOBase is that the read() method supports omitting the size argument, and does not have a default implementation that defers to readinto(). In addition, read(), readinto() and write() may raise BlockingIOError if the underlying raw stream is in non-blocking mode and not ready; unlike their raw counterparts, they will never return None. A typical implementation should not inherit from a RawIOBase implementation, but wrap one.","title":"class BufferedIOBase"},{"location":"api-docs/io/#class-iobase","text":"The abstract base class for all I/O classes, acting on streams of bytes. There is no public constructor. This class provides dummy implementations for many methods that derived classes can override selectively; the default implementations represent a file that cannot be read, written or seeked. Even though IOBase does not declare read, readinto, or write because their signatures will vary, implementations and clients should consider those methods part of the interface. Also, implementations may raise UnsupportedOperation when operations they do not support are called. The basic type used for binary data read from or written to a file is bytes. Other bytes-like objects are accepted as method arguments too. In some cases (such as readinto), a writable object is required. Text I/O classes work with str data. Note that calling any method (except additional calls to close(), which are ignored) on a closed stream should raise a ValueError. IOBase (and its subclasses) support the iterator protocol, meaning that an IOBase object can be iterated over yielding the lines in a stream. IOBase also supports the :keyword: with statement. In this example, fp is closed after the suite of the with statement is complete: with open('spam.txt', 'r') as fp: fp.write('Spam and eggs!')","title":"class IOBase"},{"location":"api-docs/io/#class-rawiobase","text":"Base class for raw binary I/O.","title":"class RawIOBase"},{"location":"api-docs/io/#class-textiobase","text":"Base class for text I/O. This class provides a character and line based interface to stream I/O. There is no readinto method because Python's character strings are immutable. There is no public constructor.","title":"class TextIOBase"},{"location":"api-docs/io/#class-unsupportedoperation","text":"This file was automatically generated via lazydocs .","title":"class UnsupportedOperation"},{"location":"api-docs/mars_features/","text":"module mars_features function compute_mars_features compute_mars_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame function compute_distance_features compute_distance_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame function compute_mars_reduced_features compute_mars_reduced_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame function compute_social_features compute_social_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame function compute_velocity_features compute_velocity_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame This file was automatically generated via lazydocs .","title":"Mars features"},{"location":"api-docs/mars_features/#module-mars_features","text":"","title":"module mars_features"},{"location":"api-docs/mars_features/#function-compute_mars_features","text":"compute_mars_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame","title":"function compute_mars_features"},{"location":"api-docs/mars_features/#function-compute_distance_features","text":"compute_distance_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame","title":"function compute_distance_features"},{"location":"api-docs/mars_features/#function-compute_mars_reduced_features","text":"compute_mars_reduced_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame","title":"function compute_mars_reduced_features"},{"location":"api-docs/mars_features/#function-compute_social_features","text":"compute_social_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame","title":"function compute_social_features"},{"location":"api-docs/mars_features/#function-compute_velocity_features","text":"compute_velocity_features( df: DataFrame, raw_col_names: list, animal_setup: dict, **kwargs ) \u2192 DataFrame This file was automatically generated via lazydocs .","title":"function compute_velocity_features"},{"location":"api-docs/ml/","text":"module ml Machine learning functions This file was automatically generated via lazydocs .","title":"Ml"},{"location":"api-docs/ml/#module-ml","text":"Machine learning functions This file was automatically generated via lazydocs .","title":"module ml"},{"location":"api-docs/plot/","text":"module plot Global Variables global_config function plot_embedding plot_embedding( dataset: VideosetDataFrame, color_col: str = None, figsize: tuple = (10, 10), **kwargs ) \u2192 tuple Scatterplot of a 2D TSNE or UMAP embedding from the dataset. Args: dataset : data, must have columns named 'embedding_0' and 'embedding_1' color_col : if provided, a column that will be used to color the points in the scatter plot figsize : tuple with the dimensions of the plot (in inches) kwargs : All other keyword pairs are sent to Matplotlib's scatter function Returns: tuple (fig, axes). The Figure and Axes objects. function plot_unsupervised_results plot_unsupervised_results(dataset, cluster_results, figsize=(15, 4), **kwargs) Set of plots for unsupervised behavior clustering results Args: dataset : data, must have columns named 'embedding_0' and 'embedding_1' cluster_results : tuple output by 'cluster_behaviors' figsize : tuple with the plot dimensions, in inches kwargs : all other keyword pairs are sent to Matplotlib's scatter function Returns: tuple (fig, axes). The Figure and Axes objects. function plot_ethogram plot_ethogram( dataset: VideosetDataFrame, vid_key: str, query_label: str = 'unsup_behavior_label', frame_limit: int = 4000, figsize: tuple = (16, 2) ) \u2192 tuple Simple ethogram of one video, up to a certain frame number. Args: dataset: - vid_key : key (in dataset.metadata) pointing to the video to make ethogram for - query_label : the column containing the behavior labels to plot - frame_limit : only make the ethogram for frames between [0, frame_limit] - figsize : tuple with figure size (in inches) Returns: tuple (fig, axes). The Figure and Axes objects function create_ethogram_video create_ethogram_video( dataset: VideosetDataFrame, vid_key: str, query_label: str, out_file: str, frame_limit: int = 4000, im_dim: float = 16, min_frames: int = 3 ) \u2192 None Overlay ethogram on top of source video with ffmpeg Args: dataset : source dataset vid_key : the key (in dataset.metadata) pointing to the video to make ethogram for. metadata must have field 'video_files' that points to the source video location query_label : the column containing the behavior labels to plot out_file : output path for created video frame_limit : only make the ethogram/video for frames [0, frame_limit] in_dim : x dimension (in inches) of ethogram min_frames : any behaviors occurring for less than this number of frames are not labeled Returns: None function create_sample_videos create_sample_videos( dataset: VideosetDataFrame, video_dir: str, out_dir: str, query_col: str = 'unsup_behavior_label', N_sample_rows: int = 16, window_size: int = 2, fps: float = 30, N_supersample_rows: int = 1000 ) \u2192 None Create a sample of videos displaying the labeled behaviors using ffmpeg. For each behavior label, randomly choose frames from the entire dataset and extract short clips from source videos based around those points. Tries to select frames where the labeled behavior is exhibited in many frames of the clip. Args: dataset : source dataset video_dir : location of source video files out_dir : base output directory to save videos. Videos are saved in the form: [out_dir]/[behavior_label]/[video_name]_[time in seconds].avi query_label : the column containing the behavior labels to extract clips for. Each unique value in this column is treated as a separate behavior N_sample_rows : number of clips to extract per behavior window_size : amount of video to extract on either side of the sampled frame, in seconds fps : frames per second of videos N_supersample_rows : this many rows are randomly sampled for each behavior label, and the top N_sample_rows are returned (in terms of number of adjacent frames also exhibiting that behavior). Shouldn't need to play with this. Returns: None function create_mosaic_video create_mosaic_video( vid_dir: str, output_file: str, ndim: tuple = (1600, 1200) ) \u2192 None Take a set of video clips and turn them into a mosaic using ffmpeg 16 videos are tiled. Args: vid_dir : source directory with videos in it output_file : output video path ndim : tuple with the output video dimensions, in pixels Returns: None class MplColorHelper method __init__ __init__(cmap_name, start_val, stop_val) method get_rgb get_rgb(val) This file was automatically generated via lazydocs .","title":"Plot"},{"location":"api-docs/plot/#module-plot","text":"","title":"module plot"},{"location":"api-docs/plot/#global-variables","text":"global_config","title":"Global Variables"},{"location":"api-docs/plot/#function-plot_embedding","text":"plot_embedding( dataset: VideosetDataFrame, color_col: str = None, figsize: tuple = (10, 10), **kwargs ) \u2192 tuple Scatterplot of a 2D TSNE or UMAP embedding from the dataset. Args: dataset : data, must have columns named 'embedding_0' and 'embedding_1' color_col : if provided, a column that will be used to color the points in the scatter plot figsize : tuple with the dimensions of the plot (in inches) kwargs : All other keyword pairs are sent to Matplotlib's scatter function Returns: tuple (fig, axes). The Figure and Axes objects.","title":"function plot_embedding"},{"location":"api-docs/plot/#function-plot_unsupervised_results","text":"plot_unsupervised_results(dataset, cluster_results, figsize=(15, 4), **kwargs) Set of plots for unsupervised behavior clustering results Args: dataset : data, must have columns named 'embedding_0' and 'embedding_1' cluster_results : tuple output by 'cluster_behaviors' figsize : tuple with the plot dimensions, in inches kwargs : all other keyword pairs are sent to Matplotlib's scatter function Returns: tuple (fig, axes). The Figure and Axes objects.","title":"function plot_unsupervised_results"},{"location":"api-docs/plot/#function-plot_ethogram","text":"plot_ethogram( dataset: VideosetDataFrame, vid_key: str, query_label: str = 'unsup_behavior_label', frame_limit: int = 4000, figsize: tuple = (16, 2) ) \u2192 tuple Simple ethogram of one video, up to a certain frame number. Args: dataset: - vid_key : key (in dataset.metadata) pointing to the video to make ethogram for - query_label : the column containing the behavior labels to plot - frame_limit : only make the ethogram for frames between [0, frame_limit] - figsize : tuple with figure size (in inches) Returns: tuple (fig, axes). The Figure and Axes objects","title":"function plot_ethogram"},{"location":"api-docs/plot/#function-create_ethogram_video","text":"create_ethogram_video( dataset: VideosetDataFrame, vid_key: str, query_label: str, out_file: str, frame_limit: int = 4000, im_dim: float = 16, min_frames: int = 3 ) \u2192 None Overlay ethogram on top of source video with ffmpeg Args: dataset : source dataset vid_key : the key (in dataset.metadata) pointing to the video to make ethogram for. metadata must have field 'video_files' that points to the source video location query_label : the column containing the behavior labels to plot out_file : output path for created video frame_limit : only make the ethogram/video for frames [0, frame_limit] in_dim : x dimension (in inches) of ethogram min_frames : any behaviors occurring for less than this number of frames are not labeled Returns: None","title":"function create_ethogram_video"},{"location":"api-docs/plot/#function-create_sample_videos","text":"create_sample_videos( dataset: VideosetDataFrame, video_dir: str, out_dir: str, query_col: str = 'unsup_behavior_label', N_sample_rows: int = 16, window_size: int = 2, fps: float = 30, N_supersample_rows: int = 1000 ) \u2192 None Create a sample of videos displaying the labeled behaviors using ffmpeg. For each behavior label, randomly choose frames from the entire dataset and extract short clips from source videos based around those points. Tries to select frames where the labeled behavior is exhibited in many frames of the clip. Args: dataset : source dataset video_dir : location of source video files out_dir : base output directory to save videos. Videos are saved in the form: [out_dir]/[behavior_label]/[video_name]_[time in seconds].avi query_label : the column containing the behavior labels to extract clips for. Each unique value in this column is treated as a separate behavior N_sample_rows : number of clips to extract per behavior window_size : amount of video to extract on either side of the sampled frame, in seconds fps : frames per second of videos N_supersample_rows : this many rows are randomly sampled for each behavior label, and the top N_sample_rows are returned (in terms of number of adjacent frames also exhibiting that behavior). Shouldn't need to play with this. Returns: None","title":"function create_sample_videos"},{"location":"api-docs/plot/#function-create_mosaic_video","text":"create_mosaic_video( vid_dir: str, output_file: str, ndim: tuple = (1600, 1200) ) \u2192 None Take a set of video clips and turn them into a mosaic using ffmpeg 16 videos are tiled. Args: vid_dir : source directory with videos in it output_file : output video path ndim : tuple with the output video dimensions, in pixels Returns: None","title":"function create_mosaic_video"},{"location":"api-docs/plot/#class-mplcolorhelper","text":"","title":"class MplColorHelper"},{"location":"api-docs/plot/#method-__init__","text":"__init__(cmap_name, start_val, stop_val)","title":"method __init__"},{"location":"api-docs/plot/#method-get_rgb","text":"get_rgb(val) This file was automatically generated via lazydocs .","title":"method get_rgb"},{"location":"api-docs/unsupervised/","text":"module unsupervised function compute_tsne_embedding compute_tsne_embedding( dataset: VideosetDataFrame, cols: list, N_rows: int = 20000, n_components=2, perplexity=30 ) \u2192 tuple Compute TSNE embedding. Args: dataset : Input data cols : A list of column names to produce the embedding for N_rows : A number of rows to randomly sample for the embedding. Only these rows are embedded. Returns: The tuple: function compute_morlet compute_morlet( data: ndarray, dt: float = 0.03333333333333333, n_freq: int = 5, w: float = 3 ) \u2192 ndarray function compute_density compute_density( dataset: VideosetDataFrame, embedding_extent: tuple, bandwidth: float = 0.5, n_pts: int = 300, N_sample_rows: int = 50000, rows: list = None ) \u2192 ndarray Compute kernel density estimate of embedding. Args: dataset : VideosetDataFrame with embedding data loaded in it. (Must have already populated columns named 'embedding_0', 'embedding_1') embedding_extent : the bounds in which to apply the density estimate. Has the form (xmin, xmax, ymin, ymax) bandwidth : the Gaussian kernel bandwidth. Will depend on the scale of the embedding. Can be changed to affect the number of clusters pulled out n_pts : number of points over which to evaluate the KDE N_sample_rows : number of rows to randomly sample to generate estimate rows : If provided, use these rows instead of a random sample Returns: Numpy array with KDE over the specified square region in the embedding space, with dimensions (n_pts x n_pts) function compute_watershed compute_watershed( dens_matrix: ndarray, positive_only: bool = False, cutoff: float = 0 ) \u2192 tuple Compute watershed clustering of a density matrix. Args: dens_matrix : A square 2D numpy array, output from compute_density, containing the kernel density estimate of the embedding. positive_only : Whether to apply a threshold, 'cutoff'. If applied, 'cutoff' is subtracted from dens_matrix, and any value below zero is set to zero. Useful for only focusing on high density clusters. cutoff : The cutoff value to apply if positive_only = True Returns: A numpy array with the same dimensions as dens_matrix. Each value in the array is the cluster ID for that coordinate. function cluster_behaviors cluster_behaviors( dataset: VideosetDataFrame, feature_cols: list, N_rows: int = 200000, use_morlet: bool = False, use_umap: bool = True, n_pts: int = 300, bandwidth: float = 0.5, **kwargs ) \u2192 tuple Cluster behaviors based on dimensionality reduction, kernel density estimation, and watershed clustering. Note that this will modify the dataset dataframe in place. The following columns are added to dataset: 'embedding_index_[0/1]': the coordinates of each embedding coordinate in the returned density matrix 'unsup_behavior_label': the Watershed transform label for that row, based on its embedding coordinates. Rows whose embedding coordinate has no watershed cluster, or which fall outside the domain have value -1. Args: dataset : the VideosetDataFrame with the features of interest feature_cols : list of column names to perform the clustering on N_rows : number of rows to perform the embedding on. If 'None', then all rows are used. use_morlet : Apply Morlet wavelet transform to the feature cols before computing the embedding use_umap : If True will use UMAP dimensionality reduction, if False will use TSNE n_pts : dimension of grid the kernel density estimate is evaluated on. bandwidth : Gaussian kernel bandwidth for kernel estimate **kwargs : All other keyword parameters are sent to dimensionality reduction call (either TSNE or UMAP) Returns: A tuple with components: - dens_matrix : the (n_pts x n_pts) numpy array with the density estimate of the 2D embedding - labels : numpy array with same dimensions are dens_matrix, but with values the watershed cluster IDs - embedding_extent : the coordinates in embedding space that dens_matrix is approximating the density over This file was automatically generated via lazydocs .","title":"Unsupervised"},{"location":"api-docs/unsupervised/#module-unsupervised","text":"","title":"module unsupervised"},{"location":"api-docs/unsupervised/#function-compute_tsne_embedding","text":"compute_tsne_embedding( dataset: VideosetDataFrame, cols: list, N_rows: int = 20000, n_components=2, perplexity=30 ) \u2192 tuple Compute TSNE embedding. Args: dataset : Input data cols : A list of column names to produce the embedding for N_rows : A number of rows to randomly sample for the embedding. Only these rows are embedded. Returns: The tuple:","title":"function compute_tsne_embedding"},{"location":"api-docs/unsupervised/#function-compute_morlet","text":"compute_morlet( data: ndarray, dt: float = 0.03333333333333333, n_freq: int = 5, w: float = 3 ) \u2192 ndarray","title":"function compute_morlet"},{"location":"api-docs/unsupervised/#function-compute_density","text":"compute_density( dataset: VideosetDataFrame, embedding_extent: tuple, bandwidth: float = 0.5, n_pts: int = 300, N_sample_rows: int = 50000, rows: list = None ) \u2192 ndarray Compute kernel density estimate of embedding. Args: dataset : VideosetDataFrame with embedding data loaded in it. (Must have already populated columns named 'embedding_0', 'embedding_1') embedding_extent : the bounds in which to apply the density estimate. Has the form (xmin, xmax, ymin, ymax) bandwidth : the Gaussian kernel bandwidth. Will depend on the scale of the embedding. Can be changed to affect the number of clusters pulled out n_pts : number of points over which to evaluate the KDE N_sample_rows : number of rows to randomly sample to generate estimate rows : If provided, use these rows instead of a random sample Returns: Numpy array with KDE over the specified square region in the embedding space, with dimensions (n_pts x n_pts)","title":"function compute_density"},{"location":"api-docs/unsupervised/#function-compute_watershed","text":"compute_watershed( dens_matrix: ndarray, positive_only: bool = False, cutoff: float = 0 ) \u2192 tuple Compute watershed clustering of a density matrix. Args: dens_matrix : A square 2D numpy array, output from compute_density, containing the kernel density estimate of the embedding. positive_only : Whether to apply a threshold, 'cutoff'. If applied, 'cutoff' is subtracted from dens_matrix, and any value below zero is set to zero. Useful for only focusing on high density clusters. cutoff : The cutoff value to apply if positive_only = True Returns: A numpy array with the same dimensions as dens_matrix. Each value in the array is the cluster ID for that coordinate.","title":"function compute_watershed"},{"location":"api-docs/unsupervised/#function-cluster_behaviors","text":"cluster_behaviors( dataset: VideosetDataFrame, feature_cols: list, N_rows: int = 200000, use_morlet: bool = False, use_umap: bool = True, n_pts: int = 300, bandwidth: float = 0.5, **kwargs ) \u2192 tuple Cluster behaviors based on dimensionality reduction, kernel density estimation, and watershed clustering. Note that this will modify the dataset dataframe in place. The following columns are added to dataset: 'embedding_index_[0/1]': the coordinates of each embedding coordinate in the returned density matrix 'unsup_behavior_label': the Watershed transform label for that row, based on its embedding coordinates. Rows whose embedding coordinate has no watershed cluster, or which fall outside the domain have value -1. Args: dataset : the VideosetDataFrame with the features of interest feature_cols : list of column names to perform the clustering on N_rows : number of rows to perform the embedding on. If 'None', then all rows are used. use_morlet : Apply Morlet wavelet transform to the feature cols before computing the embedding use_umap : If True will use UMAP dimensionality reduction, if False will use TSNE n_pts : dimension of grid the kernel density estimate is evaluated on. bandwidth : Gaussian kernel bandwidth for kernel estimate **kwargs : All other keyword parameters are sent to dimensionality reduction call (either TSNE or UMAP) Returns: A tuple with components: - dens_matrix : the (n_pts x n_pts) numpy array with the density estimate of the 2D embedding - labels : numpy array with same dimensions are dens_matrix, but with values the watershed cluster IDs - embedding_extent : the coordinates in embedding space that dens_matrix is approximating the density over This file was automatically generated via lazydocs .","title":"function cluster_behaviors"},{"location":"api-docs/utils/","text":"module utils Small helper utilities function checkFFMPEG checkFFMPEG() \u2192 bool Check for ffmpeg dependencies Returns: True if can find ffmpeg in path, false otherwise This file was automatically generated via lazydocs .","title":"Utils"},{"location":"api-docs/utils/#module-utils","text":"Small helper utilities","title":"module utils"},{"location":"api-docs/utils/#function-checkffmpeg","text":"checkFFMPEG() \u2192 bool Check for ffmpeg dependencies Returns: True if can find ffmpeg in path, false otherwise This file was automatically generated via lazydocs .","title":"function checkFFMPEG"},{"location":"api-docs/video/","text":"module video Basic video tracking and behavior class that houses data Global Variables global_config function clone_metadata clone_metadata(tracking_files: list, **kwargs) \u2192 dict Prepare a metadata dictionary for defining a VideosetDataFrame. Only required argument is list of DLC tracking file names. Any other keyword argument must be either a non-iterable object (e.g. a scalar parameter, like FPS) that will be copied and tagged to each of the DLC tracking files, or an iterable object of the same length of the list of DLC tracking files. Each element in the iterable will be tagged with the corresponding DLC file. Args: tracking_files : List of DLC tracking .csvs **kwargs : described as above Returns: Dictionary whose keys are DLC tracking file names, and contains a dictionary with key,values containing the metadata provided function load_videodataset load_videodataset(fn_in: str) \u2192 VideosetDataFrame Load VideosetDataFrame from file. Args: fn_in : path to file to load Returns: VideosetDataFrame object from pickle file class MLDataFrame DataFrame useful for interfacing between pandas and sklearn. Stores a data table and metadata dictionary. When feature columns, label columns and fold columns are specified then creates properties features, labels, folds and splitter that sklearn accepts for ML. method __init__ __init__( data: DataFrame, metadata: dict = {}, fold_cols=None, feature_cols=None, label_cols=None ) property features property folds property labels property splitter method add_data add_data(new_data, col_names) method save save(fn) class VideosetDataFrame method __init__ __init__( metadata: dict, label_key: dict = None, part_renamer: dict = None, animal_renamer: dict = None ) Houses DLC tracking data and behavior annotations in pandas DataFrame for ML, along with relevant metadata, features and behavior annotation labels. Args: metadata : Dictionary whose keys are DLC tracking csvs, and value is a dictionary of associated metadata for that video. Most easiest to create with 'clone_metadata'. Required keys are : ['fps', 'label_files'] label_key : Default None. Dictionary whose keys are behavior labels and values are integers part_renamer : Default None. Dictionary that can rename body parts from tracking files if needed (for feature creation, e.g.) animal_renamer : Default None. Dictionary that can rename animals from tracking files if needed property features property folds property group property labels property n_videos property splitter property videos method activate_features_by_name activate_features_by_name(name: str) \u2192 list Add already present columns in data frame to the feature set. Args: name : string for pattern matching -- any feature that starts with this string will be added Returns: List of matched columns (may include columns that were already activated). method add_data add_data(new_data, col_names) method add_features add_features( feature_maker: Features, featureset_name: str, add_to_features=False, **kwargs ) \u2192 list Compute features to dataframe using Feature object. 'featureset_name' will be prepended to new columns, followed by a double underscore. Args: featuremaker : A Feature object that houses the feature-making function to be executed and a list of required columns that must in the dataframe for this to work featureset_name : Name to prepend to the added features add_to_features : Whether to add to list of active features (i.e. will be returned by the .features property) Returns: List of new columns that are computed method get_columns_regex get_columns_regex(pattern: str) \u2192 list Return a list of column names that match the provided regex pattern. Args: pattern : a regex pattern to match column names to Returns: list of column names method load load(fn_in: str) \u2192 None Load VideosetDataFrame object from pickle file. Args: fn_in : path to load pickle file from. Returns: None. Data in this object is populated with contents of file. method make_movie make_movie(label_columns, path_out: str, video_filenames=None) \u2192 None Given columns indicating behavior predictions or whatever else, make a video with these predictions overlaid. VideosetDataFrame must have the keys 'video_file', so that the video associated with each set of DLC tracks is known. Args: label_columns : list or dict of columns whose values to overlay on top of video. If dict, keys are the columns and values are the print-friendly version. path_out : the directory to output the videos too video_filenames : list or string. The Returns: None. Videos are saved to 'path_out' method remove_feature_cols remove_feature_cols(col_names: list) \u2192 list Remove provided columns from set of feature columns. Args: col_names : list of column names Returns: The columns that were removed from those designated as features. method remove_features_by_name remove_features_by_name(name: str) \u2192 list Remove columns from the feature set. Args: name : string for pattern matching -- any feature that starts with this string will be removed Returns: List of removed columns. method save save(fn_out: str) \u2192 None Save VideosetDataFrame object with pickle. Args: fn_out : location to write pickle file to Returns: None. File is saved to path. This file was automatically generated via lazydocs .","title":"Video"},{"location":"api-docs/video/#module-video","text":"Basic video tracking and behavior class that houses data","title":"module video"},{"location":"api-docs/video/#global-variables","text":"global_config","title":"Global Variables"},{"location":"api-docs/video/#function-clone_metadata","text":"clone_metadata(tracking_files: list, **kwargs) \u2192 dict Prepare a metadata dictionary for defining a VideosetDataFrame. Only required argument is list of DLC tracking file names. Any other keyword argument must be either a non-iterable object (e.g. a scalar parameter, like FPS) that will be copied and tagged to each of the DLC tracking files, or an iterable object of the same length of the list of DLC tracking files. Each element in the iterable will be tagged with the corresponding DLC file. Args: tracking_files : List of DLC tracking .csvs **kwargs : described as above Returns: Dictionary whose keys are DLC tracking file names, and contains a dictionary with key,values containing the metadata provided","title":"function clone_metadata"},{"location":"api-docs/video/#function-load_videodataset","text":"load_videodataset(fn_in: str) \u2192 VideosetDataFrame Load VideosetDataFrame from file. Args: fn_in : path to file to load Returns: VideosetDataFrame object from pickle file","title":"function load_videodataset"},{"location":"api-docs/video/#class-mldataframe","text":"DataFrame useful for interfacing between pandas and sklearn. Stores a data table and metadata dictionary. When feature columns, label columns and fold columns are specified then creates properties features, labels, folds and splitter that sklearn accepts for ML.","title":"class MLDataFrame"},{"location":"api-docs/video/#method-__init__","text":"__init__( data: DataFrame, metadata: dict = {}, fold_cols=None, feature_cols=None, label_cols=None )","title":"method __init__"},{"location":"api-docs/video/#property-features","text":"","title":"property features"},{"location":"api-docs/video/#property-folds","text":"","title":"property folds"},{"location":"api-docs/video/#property-labels","text":"","title":"property labels"},{"location":"api-docs/video/#property-splitter","text":"","title":"property splitter"},{"location":"api-docs/video/#method-add_data","text":"add_data(new_data, col_names)","title":"method add_data"},{"location":"api-docs/video/#method-save","text":"save(fn)","title":"method save"},{"location":"api-docs/video/#class-videosetdataframe","text":"","title":"class VideosetDataFrame"},{"location":"api-docs/video/#method-__init___1","text":"__init__( metadata: dict, label_key: dict = None, part_renamer: dict = None, animal_renamer: dict = None ) Houses DLC tracking data and behavior annotations in pandas DataFrame for ML, along with relevant metadata, features and behavior annotation labels. Args: metadata : Dictionary whose keys are DLC tracking csvs, and value is a dictionary of associated metadata for that video. Most easiest to create with 'clone_metadata'. Required keys are : ['fps', 'label_files'] label_key : Default None. Dictionary whose keys are behavior labels and values are integers part_renamer : Default None. Dictionary that can rename body parts from tracking files if needed (for feature creation, e.g.) animal_renamer : Default None. Dictionary that can rename animals from tracking files if needed","title":"method __init__"},{"location":"api-docs/video/#property-features_1","text":"","title":"property features"},{"location":"api-docs/video/#property-folds_1","text":"","title":"property folds"},{"location":"api-docs/video/#property-group","text":"","title":"property group"},{"location":"api-docs/video/#property-labels_1","text":"","title":"property labels"},{"location":"api-docs/video/#property-n_videos","text":"","title":"property n_videos"},{"location":"api-docs/video/#property-splitter_1","text":"","title":"property splitter"},{"location":"api-docs/video/#property-videos","text":"","title":"property videos"},{"location":"api-docs/video/#method-activate_features_by_name","text":"activate_features_by_name(name: str) \u2192 list Add already present columns in data frame to the feature set. Args: name : string for pattern matching -- any feature that starts with this string will be added Returns: List of matched columns (may include columns that were already activated).","title":"method activate_features_by_name"},{"location":"api-docs/video/#method-add_data_1","text":"add_data(new_data, col_names)","title":"method add_data"},{"location":"api-docs/video/#method-add_features","text":"add_features( feature_maker: Features, featureset_name: str, add_to_features=False, **kwargs ) \u2192 list Compute features to dataframe using Feature object. 'featureset_name' will be prepended to new columns, followed by a double underscore. Args: featuremaker : A Feature object that houses the feature-making function to be executed and a list of required columns that must in the dataframe for this to work featureset_name : Name to prepend to the added features add_to_features : Whether to add to list of active features (i.e. will be returned by the .features property) Returns: List of new columns that are computed","title":"method add_features"},{"location":"api-docs/video/#method-get_columns_regex","text":"get_columns_regex(pattern: str) \u2192 list Return a list of column names that match the provided regex pattern. Args: pattern : a regex pattern to match column names to Returns: list of column names","title":"method get_columns_regex"},{"location":"api-docs/video/#method-load","text":"load(fn_in: str) \u2192 None Load VideosetDataFrame object from pickle file. Args: fn_in : path to load pickle file from. Returns: None. Data in this object is populated with contents of file.","title":"method load"},{"location":"api-docs/video/#method-make_movie","text":"make_movie(label_columns, path_out: str, video_filenames=None) \u2192 None Given columns indicating behavior predictions or whatever else, make a video with these predictions overlaid. VideosetDataFrame must have the keys 'video_file', so that the video associated with each set of DLC tracks is known. Args: label_columns : list or dict of columns whose values to overlay on top of video. If dict, keys are the columns and values are the print-friendly version. path_out : the directory to output the videos too video_filenames : list or string. The Returns: None. Videos are saved to 'path_out'","title":"method make_movie"},{"location":"api-docs/video/#method-remove_feature_cols","text":"remove_feature_cols(col_names: list) \u2192 list Remove provided columns from set of feature columns. Args: col_names : list of column names Returns: The columns that were removed from those designated as features.","title":"method remove_feature_cols"},{"location":"api-docs/video/#method-remove_features_by_name","text":"remove_features_by_name(name: str) \u2192 list Remove columns from the feature set. Args: name : string for pattern matching -- any feature that starts with this string will be removed Returns: List of removed columns.","title":"method remove_features_by_name"},{"location":"api-docs/video/#method-save_1","text":"save(fn_out: str) \u2192 None Save VideosetDataFrame object with pickle. Args: fn_out : location to write pickle file to Returns: None. File is saved to path. This file was automatically generated via lazydocs .","title":"method save"}]}